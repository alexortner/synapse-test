{
	"name": "1_Demo_Files_Metastore_Spark",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "Sparkpool01",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "e3152304-7a4d-4d35-883c-d6e41d5d23dc"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/09a38f01-eb6d-4b29-8759-eaac6c6e0933/resourceGroups/lht_workshop/providers/Microsoft.Synapse/workspaces/lht-workshop-prepration/bigDataPools/Sparkpool01",
				"name": "Sparkpool01",
				"type": "Spark",
				"endpoint": "https://lht-workshop-prepration.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/Sparkpool01",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"import pyspark.sql.functions as f\n",
					"bucket = \"abfss://lht@lhtdata.dfs.core.windows.net/\""
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"source": [
					"%run helpers"
				],
				"execution_count": 3
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Check the data files on the storage "
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# Look on the storage\n",
					"list_files_tree(f\"{bucket}\",0,0)"
				],
				"execution_count": 64
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"In Spark the three Level Namespace consists of \n",
					"* First Level = Catalog\n",
					"* Second Level = Database\n",
					"* Third Level = Table"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Check the catalog, database and tables in the metastore"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"-- check which catalog is connected to Spark\n",
					"-- spark_catalog == lake database\n",
					"-- First Level\n",
					"\n",
					"SHOW CATALOGS"
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"-- SECOND LEVEL\n",
					"SHOW DATABASES in spark_catalog"
				],
				"execution_count": 17
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Load and Query data in different ways\n",
					"\n",
					"1. directly from file\n",
					"2. register existing file as external talbe\n",
					"3. create managed table and fill with data\n",
					"\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Read direct file read"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"df_from_file = (spark\n",
					"    # read file\n",
					"    .read.format('delta').load('abfss://lht@lhtdata.dfs.core.windows.net/airport.delta')\n",
					"    # filter\n",
					"    .filter(f.col(\"country_code\")=='DE')\n",
					"    .sort(f.col(\"city_name\"))\n",
					"    .limit(5)\n",
					"    )\n",
					"\n",
					"\n",
					"display(df_from_file)"
				],
				"execution_count": 21
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Read via table definition\n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					}
				},
				"source": [
					"%%sql\n",
					"-- create new database with root storage in our storage containter\n",
					"CREATE DATABASE flight_data\n",
					"LOCATION 'abfss://lht@lhtdata.dfs.core.windows.net/flight_data'"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"# current tables in database\n",
					"show_table_details(\"flight_data\")"
				],
				"execution_count": 28
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Register existing Delta files as external table"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"-- register existing delta file as a table with a new name\n",
					"CREATE EXTERNAL TABLE IF NOT EXISTS flight_data.airport_registered_from_spark\n",
					"USING DELTA\n",
					"LOCATION 'abfss://lht@lhtdata.dfs.core.windows.net/airport.delta';"
				],
				"execution_count": 31
			},
			{
				"cell_type": "code",
				"source": [
					"# current tables in database\n",
					"show_table_details(\"flight_data\")"
				],
				"execution_count": 32
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"# pyspark - dataframe API\n",
					"df_from_table = (spark\n",
					"    # read table\n",
					"    .read.table(\"flight_data.airport_registered_from_spark\")\n",
					"    # filter\n",
					"    .filter(f.col(\"country_code\")=='DE')\n",
					"    .sort(f.col(\"city_name\"))\n",
					"    .limit(5)\n",
					"    )\n",
					"\n",
					"\n",
					"display(df_from_table)"
				],
				"execution_count": 33
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"-- spark sql api\n",
					"\n",
					"-- Read data from table defined in Metastore via Spark SQL\n",
					"SELECT\n",
					"    name,city_name, country_name, iata, icao \n",
					"FROM \n",
					"    flight_data.airport_registered_from_spark\n",
					"WHERE country_code = 'DE'\n",
					"ORDER BY city_name\n",
					"LIMIT 5"
				],
				"execution_count": 34
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Create a new external table in some storage\n",
					"* this time a new external table is registered on a folder that is so far empty with no Delta file "
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"-- register new empty delta file on an external path\n",
					"CREATE EXTERNAL TABLE IF NOT EXISTS flight_data.airport_new_from_spark\n",
					"USING DELTA\n",
					"LOCATION 'abfss://lht@lhtdata.dfs.core.windows.net/external_tables/airport_new_from_spark.delta';"
				],
				"execution_count": 43
			},
			{
				"cell_type": "code",
				"source": [
					"# current tables in Metastore\n",
					"show_table_details(\"flight_data\")"
				],
				"execution_count": 44
			},
			{
				"cell_type": "code",
				"source": [
					"#%%sql\n",
					"#-- SELECT * FROM flight_data.airport_new_from_spark"
				],
				"execution_count": 48
			},
			{
				"cell_type": "code",
				"source": [
					"# Add ata to the empty created delta table\n",
					"(df_from_file.write\n",
					"  .format(\"delta\")\n",
					"  .mode(\"append\")\n",
					"  # the empty table has no schema, now we need to force it to overwrite it with the schea\n",
					"  .option(\"mergeSchema\", \"true\")\n",
					"  .saveAsTable(f\"flight_data.airport_new_from_spark\")\n",
					"  )"
				],
				"execution_count": 50
			},
			{
				"cell_type": "code",
				"source": [
					"# show table\n",
					"spark.sql(\"\"\"\n",
					"    SELECT\n",
					"        name,city_name, country_name, iata, icao \n",
					"    FROM \n",
					"        flight_data.airport_new_from_spark\n",
					"    WHERE country_code = 'DE'\n",
					"    ORDER BY city_name\n",
					"    LIMIT 5\n",
					"\"\"\").show()"
				],
				"execution_count": 52
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Managed Tables\n",
					"\n",
					"For managed tables the data and the storage location is managed by the catalog. Here the table files are stored in the default location of the database we defined when creating the databae"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# Register it to the Lake Database metastore\n",
					"(df_from_file.write\n",
					"  .format(\"delta\")\n",
					"  .mode(\"overwrite\")\n",
					"  .saveAsTable(f\"flight_data.airport_managed\")\n",
					"  )"
				],
				"execution_count": 53
			},
			{
				"cell_type": "code",
				"source": [
					"# current tables in Metastore\n",
					"show_table_details(\"flight_data\")\n",
					"\n",
					"print(\"    \")\n",
					"print(\"####################################################################\")\n",
					"print(\"    \")\n",
					"\n",
					"list_files_tree(f\"{bucket}/flight_data\",0,1)"
				],
				"execution_count": 58
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"-- Read data from table defined in Metastore via Spark SQL\n",
					"SELECT\n",
					"    name,city_name, country_name, iata, icao \n",
					"FROM \n",
					"    flight_data.airport_managed\n",
					"WHERE country_code = 'DE'\n",
					"ORDER BY city_name\n",
					"LIMIT 5"
				],
				"execution_count": 59
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Difference of managed and external tables\n",
					"* drop of managed table removes metastore entry and deletes underlying data\n",
					"* drop of external table only removes metastore entry"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"spark.sql(\"DROP TABLE IF EXISTS flight_data.airport_managed\")\n",
					"show_table_details(\"flight_data\")\n",
					"\n",
					"print(\"    \")\n",
					"print(\"####################################################################\")\n",
					"print(\"    \")\n",
					"\n",
					"list_files_tree(f\"{bucket}/\",0,2)"
				],
				"execution_count": 61
			},
			{
				"cell_type": "code",
				"source": [
					"spark.sql(\"DROP TABLE IF EXISTS flight_data.airport_new_from_spark\")\n",
					"show_table_details(\"flight_data\")\n",
					"\n",
					"print(\"    \")\n",
					"print(\"####################################################################\")\n",
					"print(\"    \")\n",
					"\n",
					"list_files_tree(f\"{bucket}\",0,2)"
				],
				"execution_count": 62
			},
			{
				"cell_type": "code",
				"source": [
					"spark.sql(\"DROP TABLE IF EXISTS flight_data.airport_registered_from_spark\")\n",
					"show_table_details(\"flight_data\")\n",
					"\n",
					"print(\"####################################################################\")\n",
					"list_files_tree(f\"{bucket}\",0,2)\n",
					""
				],
				"execution_count": 65
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"-- register existing delta file as a table with a new name\n",
					"CREATE EXTERNAL TABLE IF NOT EXISTS flight_data.airport_registered_from_spark\n",
					"USING DELTA\n",
					"LOCATION 'abfss://lht@lhtdata.dfs.core.windows.net/airport.delta';"
				],
				"execution_count": 66
			},
			{
				"cell_type": "code",
				"source": [
					"spark.stop()"
				],
				"execution_count": 24
			},
			{
				"cell_type": "code",
				"source": [
					"# full clean clean up\n",
					"\n",
					"spark.sql(\"DROP TABLE IF EXISTS flight_data.airport\")\n",
					"spark.sql(\"DROP TABLE IF EXISTS flight_data.airport_registered_from_spark\")\n",
					"spark.sql(\"DROP TABLE IF EXISTS flight_data.airport_new_from_spark\")\n",
					"spark.sql(\"DROP TABLE IF EXISTS flight_data.airport_managed\")\n",
					"\n",
					"\n",
					"show_table_details(\"flight_data\")\n",
					"\n",
					"print(\"####################################################################\")\n",
					"list_files_tree(f\"{bucket}\",0,2)\n",
					"\n",
					"\n",
					"#safe_delete_path(f\"{trusted}/{user}/lab/cars\")\n",
					"#safe_delete_path(f\"{trusted}/{user}/lab/juices\")"
				],
				"execution_count": null
			}
		]
	}
}